version: '3'
services:
  mt-helsinki-nlp: # for building from source
    build:
      context: .
      dockerfile: Dockerfile
    # or use image: qanary/qanary-component-mt-python-helsinki-nlp:latest
    network_mode: host # or use ports
    restart: unless-stopped
    volumes:
      - /path/to/huggingface-docker-cache:/root/.cache/huggingface/transformers # for caching huggingface models